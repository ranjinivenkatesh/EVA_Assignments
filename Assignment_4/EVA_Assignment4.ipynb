{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA_Assignment4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Installs and imports deep learning library keras\n",
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import required python packages required for processing\n",
        "import numpy as np\n",
        "\n",
        "#import sequential model type of keras where layers are added one by one\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNSS2DeB2zg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9a80cb4a-bbcf-42ef-f9a7-7691b94b2916"
      },
      "source": [
        "#split the mnist dataset to training and test datasets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "6da921d8-fa0d-40a6-b1f2-ecf861f87eda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "#Print the dimension of training dataset of mnist and  first training image\n",
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe6f1130e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reshaped Train and Test datasets from (60000,28,28) to (60000, 28,28,1) by taking into input channels \n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Ascertaining Value type of float and Normalising the values of pixels to be between 0 and 1\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "2edfe3fc-4ce0-4267-d699-bbb537a169be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Print the actual outputs of first 10 training datasets\n",
        "y_train[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "192a98e6-dce2-4f35-c6c0-673dbac6b885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "#Print the actual outputs of first 10 training datasets as categorical values \n",
        "Y_train[:10]\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JWKx7tWtLYJ",
        "colab_type": "text"
      },
      "source": [
        "1. PLAIN VANILLA NETWORK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_khnrZxVrL6",
        "colab_type": "text"
      },
      "source": [
        "This a plain vanila model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZR-st90Xwt4",
        "colab_type": "text"
      },
      "source": [
        "This model has just 3 X 3 convolutions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "d162cf1f-e20b-475b-f967-9b704ae18572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "#Generate a model for training the mnsit dataset\n",
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3,input_shape=(28,28,1)))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(16,3,3))\n",
        "model.add(Activation('relu'))\n",
        "          \n",
        "model.add(Convolution2D(24,3,3))\n",
        "model.add(Activation('relu'))    \n",
        "\n",
        "model.add(Convolution2D(32,3,3))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(8,3,3))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(16,3,3))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(24,3,3))\n",
        "model.add(Activation('relu'))\n",
        " \n",
        "model.add(Convolution2D(32,3,3))\n",
        "model.add(Activation('relu'))  \n",
        "       \n",
        "model.add(Convolution2D(8,3,3))\n",
        "model.add(Activation('relu'))     \n",
        "          \n",
        "model.add(Convolution2D(16,3,3))\n",
        "model.add(Activation('relu'))\n",
        "          \n",
        "model.add(Convolution2D(24,3,3))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(32,3,3))\n",
        "model.add(Activation('relu'))\n",
        "          \n",
        "model.add(Convolution2D(10,4,4))\n",
        "model.add(Activation('relu'))          \n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3))`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3))`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzdAYg1k9K7Z",
        "colab_type": "code",
        "outputId": "702db778-0b75-48dc-e9a5-dd0b00e66700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Print Model Summary giving the number of parameters\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_36 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "activation_38 (Activation)   (None, 26, 26, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 24, 24, 16)        1168      \n",
            "_________________________________________________________________\n",
            "activation_39 (Activation)   (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 22, 22, 24)        3480      \n",
            "_________________________________________________________________\n",
            "activation_40 (Activation)   (None, 22, 22, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 20, 20, 32)        6944      \n",
            "_________________________________________________________________\n",
            "activation_41 (Activation)   (None, 20, 20, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 18, 18, 8)         2312      \n",
            "_________________________________________________________________\n",
            "activation_42 (Activation)   (None, 18, 18, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 16, 16, 16)        1168      \n",
            "_________________________________________________________________\n",
            "activation_43 (Activation)   (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 14, 14, 24)        3480      \n",
            "_________________________________________________________________\n",
            "activation_44 (Activation)   (None, 14, 14, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 12, 12, 32)        6944      \n",
            "_________________________________________________________________\n",
            "activation_45 (Activation)   (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 10, 10, 8)         2312      \n",
            "_________________________________________________________________\n",
            "activation_46 (Activation)   (None, 10, 10, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 8, 8, 16)          1168      \n",
            "_________________________________________________________________\n",
            "activation_47 (Activation)   (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 6, 6, 24)          3480      \n",
            "_________________________________________________________________\n",
            "activation_48 (Activation)   (None, 6, 6, 24)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_47 (Conv2D)           (None, 4, 4, 32)          6944      \n",
            "_________________________________________________________________\n",
            "activation_49 (Activation)   (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_48 (Conv2D)           (None, 1, 1, 10)          5130      \n",
            "_________________________________________________________________\n",
            "activation_50 (Activation)   (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_51 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 44,610\n",
            "Trainable params: 44,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the above model with loss type of categorical_crossentropy as the output is categorical type\n",
        "# optimizer 'adam' is based on stochastic gradient which is efficient \n",
        "from keras.optimizers import Adam\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='Adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "0c15e91b-816d-48fb-c5bf-6ad5c1392b8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Train the model with batch_size of 32 and for 10 epochs\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=40, verbose=1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "60000/60000 [==============================] - 37s 619us/step - loss: 0.7500 - acc: 0.7312\n",
            "Epoch 2/40\n",
            "60000/60000 [==============================] - 36s 598us/step - loss: 0.5781 - acc: 0.7732\n",
            "Epoch 3/40\n",
            "60000/60000 [==============================] - 36s 602us/step - loss: 0.5500 - acc: 0.7793\n",
            "Epoch 4/40\n",
            "60000/60000 [==============================] - 36s 600us/step - loss: 0.5394 - acc: 0.7807\n",
            "Epoch 5/40\n",
            "60000/60000 [==============================] - 36s 597us/step - loss: 0.5299 - acc: 0.7833\n",
            "Epoch 6/40\n",
            "60000/60000 [==============================] - 36s 603us/step - loss: 0.5230 - acc: 0.7846\n",
            "Epoch 7/40\n",
            "60000/60000 [==============================] - 36s 598us/step - loss: 0.5184 - acc: 0.7855\n",
            "Epoch 8/40\n",
            "60000/60000 [==============================] - 36s 598us/step - loss: 0.5148 - acc: 0.7861\n",
            "Epoch 9/40\n",
            "60000/60000 [==============================] - 36s 602us/step - loss: 0.5132 - acc: 0.7869\n",
            "Epoch 10/40\n",
            "60000/60000 [==============================] - 36s 597us/step - loss: 0.5095 - acc: 0.7874\n",
            "Epoch 11/40\n",
            "60000/60000 [==============================] - 36s 596us/step - loss: 0.5092 - acc: 0.7879\n",
            "Epoch 12/40\n",
            "60000/60000 [==============================] - 36s 598us/step - loss: 0.5064 - acc: 0.7882\n",
            "Epoch 13/40\n",
            "60000/60000 [==============================] - 36s 598us/step - loss: 0.5059 - acc: 0.7885\n",
            "Epoch 14/40\n",
            "60000/60000 [==============================] - 36s 602us/step - loss: 0.5041 - acc: 0.7889\n",
            "Epoch 15/40\n",
            "60000/60000 [==============================] - 36s 597us/step - loss: 0.5035 - acc: 0.7887\n",
            "Epoch 16/40\n",
            "60000/60000 [==============================] - 36s 597us/step - loss: 0.5020 - acc: 0.7890\n",
            "Epoch 17/40\n",
            "60000/60000 [==============================] - 36s 598us/step - loss: 0.5019 - acc: 0.7890\n",
            "Epoch 18/40\n",
            "60000/60000 [==============================] - 36s 604us/step - loss: 0.5014 - acc: 0.7890\n",
            "Epoch 19/40\n",
            "60000/60000 [==============================] - 36s 603us/step - loss: 0.5000 - acc: 0.7893\n",
            "Epoch 20/40\n",
            "60000/60000 [==============================] - 36s 597us/step - loss: 0.4999 - acc: 0.7892\n",
            "Epoch 21/40\n",
            "60000/60000 [==============================] - 36s 601us/step - loss: 0.5014 - acc: 0.7887\n",
            "Epoch 22/40\n",
            "60000/60000 [==============================] - 36s 597us/step - loss: 0.4964 - acc: 0.7899\n",
            "Epoch 23/40\n",
            "60000/60000 [==============================] - 36s 601us/step - loss: 0.4989 - acc: 0.7896\n",
            "Epoch 24/40\n",
            "60000/60000 [==============================] - 36s 598us/step - loss: 0.4981 - acc: 0.7901\n",
            "Epoch 25/40\n",
            "60000/60000 [==============================] - 36s 598us/step - loss: 0.4977 - acc: 0.7902\n",
            "Epoch 26/40\n",
            "60000/60000 [==============================] - 36s 598us/step - loss: 0.4986 - acc: 0.7897\n",
            "Epoch 27/40\n",
            "60000/60000 [==============================] - 36s 601us/step - loss: 0.4991 - acc: 0.7896\n",
            "Epoch 28/40\n",
            "60000/60000 [==============================] - 36s 600us/step - loss: 0.4986 - acc: 0.7899\n",
            "Epoch 29/40\n",
            "60000/60000 [==============================] - 36s 601us/step - loss: 0.4975 - acc: 0.7893\n",
            "Epoch 30/40\n",
            "60000/60000 [==============================] - 36s 601us/step - loss: 0.4950 - acc: 0.7904\n",
            "Epoch 31/40\n",
            "60000/60000 [==============================] - 36s 601us/step - loss: 0.4978 - acc: 0.7900\n",
            "Epoch 32/40\n",
            "60000/60000 [==============================] - 36s 600us/step - loss: 0.4971 - acc: 0.7899\n",
            "Epoch 33/40\n",
            "60000/60000 [==============================] - 36s 596us/step - loss: 0.4964 - acc: 0.7907\n",
            "Epoch 34/40\n",
            "60000/60000 [==============================] - 36s 599us/step - loss: 0.4958 - acc: 0.7904\n",
            "Epoch 35/40\n",
            "60000/60000 [==============================] - 36s 604us/step - loss: 0.4962 - acc: 0.7902\n",
            "Epoch 36/40\n",
            "60000/60000 [==============================] - 36s 594us/step - loss: 0.4960 - acc: 0.7904\n",
            "Epoch 37/40\n",
            "60000/60000 [==============================] - 36s 594us/step - loss: 0.4992 - acc: 0.7896\n",
            "Epoch 38/40\n",
            "60000/60000 [==============================] - 36s 593us/step - loss: 0.4966 - acc: 0.7903\n",
            "Epoch 39/40\n",
            "60000/60000 [==============================] - 36s 599us/step - loss: 0.4970 - acc: 0.7898\n",
            "Epoch 40/40\n",
            "60000/60000 [==============================] - 36s 600us/step - loss: 0.4953 - acc: 0.7908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe69497c7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtsH-lLk-eLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluate the trained model with Test Data set\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "ba897604-55cf-4f22-9906-9dc322e8903e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5089319506168365, 0.7887]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lLlSqbHtUcQ",
        "colab_type": "text"
      },
      "source": [
        "ACCURACY OF PLAIN VANILLA NEWTORK - 0.7887 with 44610 parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_ttUED3X7qi",
        "colab_type": "text"
      },
      "source": [
        "CONCLUSION: Accuracy needs to improve. Also, number of parameters is very high"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9MozW1McVUp",
        "colab_type": "text"
      },
      "source": [
        "=======END OF 1ST ITERATION==================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik5dXm4Gynco",
        "colab_type": "text"
      },
      "source": [
        "2- NETWORK (with MAXPOOLING AND BN)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OClACGj0Rd7X",
        "colab_type": "text"
      },
      "source": [
        "INTUITION- As seen in conclusion of Vanila Network, number of parameters is very high. So, with max pool we can reduce number of parameters. At the same time, accuracy needs to improve. So, we can use batch normalization to improve accuracy\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvGufgOE0TBc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "12dd3d16-73bc-41eb-d023-95ce11b43a1a"
      },
      "source": [
        "#Generate a model for training the mnsit dataset\n",
        "from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3,input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(16,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "          \n",
        "model.add(Convolution2D(24,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))         \n",
        "         \n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n",
        "         \n",
        "          \n",
        "model.add(Convolution2D(8,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))     \n",
        "          \n",
        "model.add(Convolution2D(16,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "          \n",
        "model.add(Convolution2D(24,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(24,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "          \n",
        "model.add(Convolution2D(10,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))          \n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3))`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oePLm0Xf-OW2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d8a2b3f-d1bf-4bcd-aa4b-5d1db733afcc"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_50 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "activation_52 (Activation)   (None, 26, 26, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_51 (Conv2D)           (None, 24, 24, 16)        1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_53 (Activation)   (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_52 (Conv2D)           (None, 22, 22, 24)        3480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 22, 22, 24)        96        \n",
            "_________________________________________________________________\n",
            "activation_54 (Activation)   (None, 22, 22, 24)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_53 (Conv2D)           (None, 9, 9, 8)           1736      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 9, 9, 8)           32        \n",
            "_________________________________________________________________\n",
            "activation_55 (Activation)   (None, 9, 9, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 7, 7, 16)          1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_56 (Activation)   (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_55 (Conv2D)           (None, 5, 5, 24)          3480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 5, 5, 24)          96        \n",
            "_________________________________________________________________\n",
            "activation_57 (Activation)   (None, 5, 5, 24)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_56 (Conv2D)           (None, 3, 3, 24)          5208      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 3, 3, 24)          96        \n",
            "_________________________________________________________________\n",
            "activation_58 (Activation)   (None, 3, 3, 24)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_57 (Conv2D)           (None, 1, 1, 10)          2170      \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "activation_59 (Activation)   (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_60 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 19,010\n",
            "Trainable params: 18,750\n",
            "Non-trainable params: 260\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgsZ7kS5-Q_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the above model with loss type of categorical_crossentropy as the output is categorical type\n",
        "# optimizer 'adam' is based on stochastic gradient which is efficient \n",
        "from keras.optimizers import Adam\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='Adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyo1K9HH-ipx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb99e15c-e2ba-4718-9a91-2761977d2d70"
      },
      "source": [
        "#Train the model with batch_size of 32 and for 40 epochs\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=40, verbose=1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "60000/60000 [==============================] - 40s 673us/step - loss: 0.4073 - acc: 0.9302\n",
            "Epoch 2/40\n",
            "60000/60000 [==============================] - 39s 643us/step - loss: 0.1481 - acc: 0.9718\n",
            "Epoch 3/40\n",
            "60000/60000 [==============================] - 39s 647us/step - loss: 0.0966 - acc: 0.9800\n",
            "Epoch 4/40\n",
            "60000/60000 [==============================] - 38s 640us/step - loss: 0.0738 - acc: 0.9837\n",
            "Epoch 5/40\n",
            "60000/60000 [==============================] - 39s 643us/step - loss: 0.0614 - acc: 0.9855\n",
            "Epoch 6/40\n",
            "60000/60000 [==============================] - 39s 647us/step - loss: 0.0540 - acc: 0.9870\n",
            "Epoch 7/40\n",
            "60000/60000 [==============================] - 39s 643us/step - loss: 0.0466 - acc: 0.9887\n",
            "Epoch 8/40\n",
            "60000/60000 [==============================] - 38s 637us/step - loss: 0.0408 - acc: 0.9900\n",
            "Epoch 9/40\n",
            "60000/60000 [==============================] - 38s 637us/step - loss: 0.0397 - acc: 0.9901\n",
            "Epoch 10/40\n",
            "60000/60000 [==============================] - 39s 644us/step - loss: 0.0334 - acc: 0.9915\n",
            "Epoch 11/40\n",
            "60000/60000 [==============================] - 39s 654us/step - loss: 0.0323 - acc: 0.9917\n",
            "Epoch 12/40\n",
            "60000/60000 [==============================] - 39s 647us/step - loss: 0.0294 - acc: 0.9924\n",
            "Epoch 13/40\n",
            "60000/60000 [==============================] - 38s 639us/step - loss: 0.0284 - acc: 0.9923\n",
            "Epoch 14/40\n",
            "60000/60000 [==============================] - 39s 643us/step - loss: 0.0261 - acc: 0.9931\n",
            "Epoch 15/40\n",
            "60000/60000 [==============================] - 39s 655us/step - loss: 0.0236 - acc: 0.9936\n",
            "Epoch 16/40\n",
            "60000/60000 [==============================] - 38s 639us/step - loss: 0.0233 - acc: 0.9936\n",
            "Epoch 17/40\n",
            "60000/60000 [==============================] - 39s 643us/step - loss: 0.0201 - acc: 0.9948\n",
            "Epoch 18/40\n",
            "60000/60000 [==============================] - 39s 647us/step - loss: 0.0201 - acc: 0.9947\n",
            "Epoch 19/40\n",
            "60000/60000 [==============================] - 39s 648us/step - loss: 0.0197 - acc: 0.9948\n",
            "Epoch 20/40\n",
            "60000/60000 [==============================] - 39s 650us/step - loss: 0.0187 - acc: 0.9948\n",
            "Epoch 21/40\n",
            "60000/60000 [==============================] - 39s 651us/step - loss: 0.0173 - acc: 0.9951\n",
            "Epoch 22/40\n",
            "60000/60000 [==============================] - 38s 638us/step - loss: 0.0174 - acc: 0.9950\n",
            "Epoch 23/40\n",
            "60000/60000 [==============================] - 39s 656us/step - loss: 0.0157 - acc: 0.9956\n",
            "Epoch 24/40\n",
            "60000/60000 [==============================] - 38s 637us/step - loss: 0.0148 - acc: 0.9957\n",
            "Epoch 25/40\n",
            "60000/60000 [==============================] - 39s 647us/step - loss: 0.0147 - acc: 0.9957\n",
            "Epoch 26/40\n",
            "60000/60000 [==============================] - 39s 648us/step - loss: 0.0129 - acc: 0.9965\n",
            "Epoch 27/40\n",
            "60000/60000 [==============================] - 39s 646us/step - loss: 0.0130 - acc: 0.9964\n",
            "Epoch 28/40\n",
            "60000/60000 [==============================] - 39s 656us/step - loss: 0.0132 - acc: 0.9968\n",
            "Epoch 29/40\n",
            "60000/60000 [==============================] - 39s 645us/step - loss: 0.0126 - acc: 0.9965\n",
            "Epoch 30/40\n",
            "60000/60000 [==============================] - 38s 640us/step - loss: 0.0117 - acc: 0.9970\n",
            "Epoch 31/40\n",
            "60000/60000 [==============================] - 39s 647us/step - loss: 0.0111 - acc: 0.9971\n",
            "Epoch 32/40\n",
            "60000/60000 [==============================] - 38s 639us/step - loss: 0.0113 - acc: 0.9970\n",
            "Epoch 33/40\n",
            "60000/60000 [==============================] - 39s 642us/step - loss: 0.0104 - acc: 0.9972\n",
            "Epoch 34/40\n",
            "60000/60000 [==============================] - 38s 641us/step - loss: 0.0095 - acc: 0.9974\n",
            "Epoch 35/40\n",
            "60000/60000 [==============================] - 39s 648us/step - loss: 0.0101 - acc: 0.9973\n",
            "Epoch 36/40\n",
            "60000/60000 [==============================] - 39s 645us/step - loss: 0.0100 - acc: 0.9973\n",
            "Epoch 37/40\n",
            "60000/60000 [==============================] - 38s 639us/step - loss: 0.0084 - acc: 0.9979\n",
            "Epoch 38/40\n",
            "60000/60000 [==============================] - 39s 644us/step - loss: 0.0096 - acc: 0.9972\n",
            "Epoch 39/40\n",
            "60000/60000 [==============================] - 39s 649us/step - loss: 0.0096 - acc: 0.9974\n",
            "Epoch 40/40\n",
            "60000/60000 [==============================] - 39s 647us/step - loss: 0.0074 - acc: 0.9978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe6946c5588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluate the trained model with Test Data set\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGt7L6CR_BRG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8de67c9d-b429-4bd1-9189-5ccc67e3aa7f"
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.021137597950210328, 0.9942]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7xfYbIYRoET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmKfkoItIKk0",
        "colab_type": "text"
      },
      "source": [
        "ACCURACY WITH BN AND MAX POOLING = 0.9942 with 19010 parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvPqbfpUYnZM",
        "colab_type": "text"
      },
      "source": [
        "CONCLUSION- As seen in this iteration, accuracy has greatly improved by using batch normalization. Also, parameters has greatly reduced by using max pool. Reduction of parameters is almost by 24k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOzYKAhdb1zu",
        "colab_type": "text"
      },
      "source": [
        "=============================END OF 2ND ITERATION===================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owv32ACjIWZO",
        "colab_type": "text"
      },
      "source": [
        "3. WITH DROPOUT AND 1X1 CONVOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXn4roJTY-FJ",
        "colab_type": "text"
      },
      "source": [
        "INTUITION- Number of parameters still need to reduce. Using Drop out to reduce the number of parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNCo-6smIrfB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "66921cad-1ff1-455e-8360-caf635bd70a2"
      },
      "source": [
        "#Generate a model for training the mnsit dataset\n",
        "from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3,input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(16,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "          \n",
        "model.add(Convolution2D(24,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))  \n",
        "model.add(Dropout(0.1))\n",
        "         \n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu'))\n",
        "         \n",
        "          \n",
        "model.add(Convolution2D(8,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))  \n",
        "model.add(Dropout(0.1))\n",
        "          \n",
        "model.add(Convolution2D(16,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "          \n",
        "model.add(Convolution2D(24,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(24,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "          \n",
        "model.add(Convolution2D(10,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu')) \n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3))`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90hhAu6dKZk9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f5c8db06-b80a-4f71-fa85-5073d5d234ad"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_58 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "activation_61 (Activation)   (None, 26, 26, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 26, 26, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 24, 24, 16)        1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_62 (Activation)   (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_60 (Conv2D)           (None, 22, 22, 24)        3480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 22, 22, 24)        96        \n",
            "_________________________________________________________________\n",
            "activation_63 (Activation)   (None, 22, 22, 24)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 22, 22, 24)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_61 (Conv2D)           (None, 11, 11, 10)        250       \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 9, 9, 8)           728       \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 9, 9, 8)           32        \n",
            "_________________________________________________________________\n",
            "activation_64 (Activation)   (None, 9, 9, 8)           0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 9, 9, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_63 (Conv2D)           (None, 7, 7, 16)          1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_65 (Activation)   (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_64 (Conv2D)           (None, 5, 5, 24)          3480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 5, 5, 24)          96        \n",
            "_________________________________________________________________\n",
            "activation_66 (Activation)   (None, 5, 5, 24)          0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 5, 5, 24)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_65 (Conv2D)           (None, 3, 3, 24)          5208      \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 3, 3, 24)          96        \n",
            "_________________________________________________________________\n",
            "activation_67 (Activation)   (None, 3, 3, 24)          0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 3, 3, 24)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_66 (Conv2D)           (None, 1, 1, 10)          2170      \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "activation_68 (Activation)   (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_69 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 18,252\n",
            "Trainable params: 17,992\n",
            "Non-trainable params: 260\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2ieBkzvJlIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the above model with loss type of categorical_crossentropy as the output is categorical type\n",
        "# optimizer 'adam' is based on stochastic gradient which is efficient \n",
        "from keras.optimizers import Adam\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='Adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JszZCOveJ_-2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "95c6e52c-3ffa-4ef9-d568-fa94331b6ceb"
      },
      "source": [
        "#Train the model with batch_size of 32 and for 40 epochs\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=40, verbose=1)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "60000/60000 [==============================] - 45s 750us/step - loss: 0.7154 - acc: 0.8033\n",
            "Epoch 2/40\n",
            "60000/60000 [==============================] - 42s 708us/step - loss: 0.4511 - acc: 0.8611\n",
            "Epoch 3/40\n",
            "60000/60000 [==============================] - 42s 705us/step - loss: 0.4006 - acc: 0.8719\n",
            "Epoch 4/40\n",
            "60000/60000 [==============================] - 42s 702us/step - loss: 0.3760 - acc: 0.8776\n",
            "Epoch 5/40\n",
            "60000/60000 [==============================] - 42s 708us/step - loss: 0.3661 - acc: 0.8780\n",
            "Epoch 6/40\n",
            "60000/60000 [==============================] - 42s 705us/step - loss: 0.3513 - acc: 0.8817\n",
            "Epoch 7/40\n",
            "60000/60000 [==============================] - 42s 708us/step - loss: 0.3431 - acc: 0.8827\n",
            "Epoch 8/40\n",
            "60000/60000 [==============================] - 42s 705us/step - loss: 0.3332 - acc: 0.8848\n",
            "Epoch 9/40\n",
            "60000/60000 [==============================] - 43s 715us/step - loss: 0.3348 - acc: 0.8831\n",
            "Epoch 10/40\n",
            "60000/60000 [==============================] - 42s 698us/step - loss: 0.3241 - acc: 0.8856\n",
            "Epoch 11/40\n",
            "60000/60000 [==============================] - 43s 714us/step - loss: 0.3272 - acc: 0.8862\n",
            "Epoch 12/40\n",
            "60000/60000 [==============================] - 42s 703us/step - loss: 0.3169 - acc: 0.8882\n",
            "Epoch 13/40\n",
            "60000/60000 [==============================] - 42s 706us/step - loss: 0.3112 - acc: 0.8899\n",
            "Epoch 14/40\n",
            "60000/60000 [==============================] - 42s 708us/step - loss: 0.3099 - acc: 0.8900\n",
            "Epoch 15/40\n",
            "60000/60000 [==============================] - 43s 712us/step - loss: 0.3076 - acc: 0.8908\n",
            "Epoch 16/40\n",
            "60000/60000 [==============================] - 43s 721us/step - loss: 0.3023 - acc: 0.8916\n",
            "Epoch 17/40\n",
            "60000/60000 [==============================] - 43s 712us/step - loss: 0.3022 - acc: 0.8912\n",
            "Epoch 18/40\n",
            "60000/60000 [==============================] - 42s 706us/step - loss: 0.2999 - acc: 0.8931\n",
            "Epoch 19/40\n",
            "60000/60000 [==============================] - 43s 709us/step - loss: 0.3052 - acc: 0.8897\n",
            "Epoch 20/40\n",
            "60000/60000 [==============================] - 43s 711us/step - loss: 0.2994 - acc: 0.8911\n",
            "Epoch 21/40\n",
            "60000/60000 [==============================] - 43s 710us/step - loss: 0.2976 - acc: 0.8916\n",
            "Epoch 22/40\n",
            "60000/60000 [==============================] - 42s 706us/step - loss: 0.2987 - acc: 0.8929\n",
            "Epoch 23/40\n",
            "60000/60000 [==============================] - 43s 709us/step - loss: 0.2901 - acc: 0.8948\n",
            "Epoch 24/40\n",
            "60000/60000 [==============================] - 43s 710us/step - loss: 0.2923 - acc: 0.8938\n",
            "Epoch 25/40\n",
            "60000/60000 [==============================] - 42s 708us/step - loss: 0.2909 - acc: 0.8940\n",
            "Epoch 26/40\n",
            "60000/60000 [==============================] - 43s 713us/step - loss: 0.2898 - acc: 0.8946\n",
            "Epoch 27/40\n",
            "60000/60000 [==============================] - 42s 700us/step - loss: 0.2880 - acc: 0.8945\n",
            "Epoch 28/40\n",
            "60000/60000 [==============================] - 43s 709us/step - loss: 0.2888 - acc: 0.8957\n",
            "Epoch 29/40\n",
            "60000/60000 [==============================] - 43s 710us/step - loss: 0.2842 - acc: 0.8961\n",
            "Epoch 30/40\n",
            "60000/60000 [==============================] - 42s 707us/step - loss: 0.2887 - acc: 0.8951\n",
            "Epoch 31/40\n",
            "60000/60000 [==============================] - 43s 710us/step - loss: 0.2885 - acc: 0.8943\n",
            "Epoch 32/40\n",
            "60000/60000 [==============================] - 43s 712us/step - loss: 0.2820 - acc: 0.8985\n",
            "Epoch 33/40\n",
            "60000/60000 [==============================] - 43s 715us/step - loss: 0.2879 - acc: 0.8944\n",
            "Epoch 34/40\n",
            "60000/60000 [==============================] - 42s 707us/step - loss: 0.2863 - acc: 0.8955\n",
            "Epoch 35/40\n",
            "60000/60000 [==============================] - 43s 718us/step - loss: 0.2797 - acc: 0.8975\n",
            "Epoch 36/40\n",
            "60000/60000 [==============================] - 43s 712us/step - loss: 0.2852 - acc: 0.8958\n",
            "Epoch 37/40\n",
            "60000/60000 [==============================] - 43s 710us/step - loss: 0.2755 - acc: 0.8991\n",
            "Epoch 38/40\n",
            "60000/60000 [==============================] - 43s 709us/step - loss: 0.2850 - acc: 0.8959\n",
            "Epoch 39/40\n",
            "60000/60000 [==============================] - 43s 708us/step - loss: 0.2818 - acc: 0.8968\n",
            "Epoch 40/40\n",
            "60000/60000 [==============================] - 43s 718us/step - loss: 0.2751 - acc: 0.8996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe693c8cbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcTvxuVuJuIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluate the trained model with Test Data set\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2WSJR9pKIXB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "609bf689-5e55-4061-e5ad-39fa6504f9ae"
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.02647291636802256, 0.9941]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdgbDZAUbK26",
        "colab_type": "text"
      },
      "source": [
        "ACCURACY OF 0.9941 with PARAMETERS OF 17,992"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7PurQozZTkz",
        "colab_type": "text"
      },
      "source": [
        "CONCLUSION- Accuracy is still good. Number of parameters has slightly reduced. \n",
        "Need to reduce further"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGs0oPoUcwKf",
        "colab_type": "text"
      },
      "source": [
        "===============END OF 3RD ITERATION==========================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foPCp2fPZgJg",
        "colab_type": "text"
      },
      "source": [
        "4. Reduce Filter Size \n",
        "INTUITION- Reduce number of filters in one layer for reducing the parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhpucBYVe1KQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "9b12c12d-3d5e-409e-d7f6-ef32d1772fd9"
      },
      "source": [
        "#Generate a model for training the mnsit dataset\n",
        "from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3,input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(16,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "          \n",
        "model.add(Convolution2D(24,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))  \n",
        "model.add(Dropout(0.1))\n",
        "         \n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu'))\n",
        "         \n",
        "          \n",
        "model.add(Convolution2D(8,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))  \n",
        "model.add(Dropout(0.1))\n",
        "          \n",
        "model.add(Convolution2D(16,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "          \n",
        "model.add(Convolution2D(24,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(16,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "          \n",
        "model.add(Convolution2D(10,3,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu')) \n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3))`\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh5QlW3ZNB1w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f4b3575-4439-447b-f6d1-bb7aa682f144"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 26, 26, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 26, 26, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 16)        1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 24)        3480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 22, 22, 24)        96        \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 22, 22, 24)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 22, 22, 24)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 10)        250       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 8)           728       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 9, 9, 8)           32        \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 9, 9, 8)           0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 9, 9, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 16)          1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 5, 5, 24)          3480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 5, 5, 24)          96        \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 5, 5, 24)          0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 5, 5, 24)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 3, 3, 16)          3472      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 3, 3, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 3, 3, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 3, 3, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 1, 1, 10)          1450      \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 15,764\n",
            "Trainable params: 15,520\n",
            "Non-trainable params: 244\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JcvQVDQNRj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "2c5d9ae8-28cb-4096-a779-2e8b2822d52e"
      },
      "source": [
        "# Compile the above model with loss type of categorical_crossentropy as the output is categorical type\n",
        "# optimizer 'adam' is based on stochastic gradient which is efficient \n",
        "from keras.optimizers import Adam\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='Adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7YxtIrRNbdl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "35d8ccc6-3c73-4a0a-ff2a-504be08c1979"
      },
      "source": [
        "#Train the model with batch_size of 32 and for 40 epochs\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=40, verbose=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/40\n",
            "60000/60000 [==============================] - 51s 851us/step - loss: 0.7388 - acc: 0.7961\n",
            "Epoch 2/40\n",
            "60000/60000 [==============================] - 45s 744us/step - loss: 0.4603 - acc: 0.8588\n",
            "Epoch 3/40\n",
            "60000/60000 [==============================] - 45s 754us/step - loss: 0.4072 - acc: 0.8701\n",
            "Epoch 4/40\n",
            "60000/60000 [==============================] - 44s 732us/step - loss: 0.3929 - acc: 0.8720\n",
            "Epoch 5/40\n",
            "60000/60000 [==============================] - 44s 726us/step - loss: 0.3809 - acc: 0.8743\n",
            "Epoch 6/40\n",
            "60000/60000 [==============================] - 44s 729us/step - loss: 0.3676 - acc: 0.8782\n",
            "Epoch 7/40\n",
            "60000/60000 [==============================] - 44s 730us/step - loss: 0.3620 - acc: 0.8784\n",
            "Epoch 8/40\n",
            "60000/60000 [==============================] - 44s 730us/step - loss: 0.3476 - acc: 0.8819\n",
            "Epoch 9/40\n",
            "60000/60000 [==============================] - 44s 728us/step - loss: 0.3355 - acc: 0.8856\n",
            "Epoch 10/40\n",
            "60000/60000 [==============================] - 45s 743us/step - loss: 0.3394 - acc: 0.8827\n",
            "Epoch 11/40\n",
            "60000/60000 [==============================] - 44s 734us/step - loss: 0.3331 - acc: 0.8839\n",
            "Epoch 12/40\n",
            "60000/60000 [==============================] - 44s 733us/step - loss: 0.3290 - acc: 0.8860\n",
            "Epoch 13/40\n",
            "60000/60000 [==============================] - 44s 731us/step - loss: 0.3293 - acc: 0.8848\n",
            "Epoch 14/40\n",
            "60000/60000 [==============================] - 44s 727us/step - loss: 0.3239 - acc: 0.8862\n",
            "Epoch 15/40\n",
            "60000/60000 [==============================] - 44s 729us/step - loss: 0.3221 - acc: 0.8875\n",
            "Epoch 16/40\n",
            "60000/60000 [==============================] - 44s 726us/step - loss: 0.3183 - acc: 0.8884\n",
            "Epoch 17/40\n",
            "60000/60000 [==============================] - 44s 732us/step - loss: 0.3186 - acc: 0.8873\n",
            "Epoch 18/40\n",
            "60000/60000 [==============================] - 44s 736us/step - loss: 0.3117 - acc: 0.8891\n",
            "Epoch 19/40\n",
            "60000/60000 [==============================] - 45s 742us/step - loss: 0.3096 - acc: 0.8892\n",
            "Epoch 20/40\n",
            "60000/60000 [==============================] - 45s 752us/step - loss: 0.3103 - acc: 0.8909\n",
            "Epoch 21/40\n",
            "60000/60000 [==============================] - 45s 755us/step - loss: 0.3008 - acc: 0.8938\n",
            "Epoch 22/40\n",
            "60000/60000 [==============================] - 45s 758us/step - loss: 0.3102 - acc: 0.8883\n",
            "Epoch 23/40\n",
            "60000/60000 [==============================] - 45s 751us/step - loss: 0.3021 - acc: 0.8924\n",
            "Epoch 24/40\n",
            "60000/60000 [==============================] - 46s 759us/step - loss: 0.3016 - acc: 0.8929\n",
            "Epoch 25/40\n",
            "60000/60000 [==============================] - 46s 768us/step - loss: 0.2938 - acc: 0.8947\n",
            "Epoch 26/40\n",
            "60000/60000 [==============================] - 46s 764us/step - loss: 0.2987 - acc: 0.8932\n",
            "Epoch 27/40\n",
            "60000/60000 [==============================] - 45s 754us/step - loss: 0.3011 - acc: 0.8926\n",
            "Epoch 28/40\n",
            "60000/60000 [==============================] - 45s 744us/step - loss: 0.2932 - acc: 0.8943\n",
            "Epoch 29/40\n",
            "60000/60000 [==============================] - 45s 755us/step - loss: 0.2992 - acc: 0.8922\n",
            "Epoch 30/40\n",
            "60000/60000 [==============================] - 45s 745us/step - loss: 0.2971 - acc: 0.8933\n",
            "Epoch 31/40\n",
            "60000/60000 [==============================] - 45s 743us/step - loss: 0.2968 - acc: 0.8948\n",
            "Epoch 32/40\n",
            "60000/60000 [==============================] - 44s 741us/step - loss: 0.2953 - acc: 0.8942\n",
            "Epoch 33/40\n",
            "60000/60000 [==============================] - 45s 743us/step - loss: 0.2981 - acc: 0.8920\n",
            "Epoch 34/40\n",
            "60000/60000 [==============================] - 45s 753us/step - loss: 0.2998 - acc: 0.8923\n",
            "Epoch 35/40\n",
            "60000/60000 [==============================] - 45s 755us/step - loss: 0.2927 - acc: 0.8949\n",
            "Epoch 36/40\n",
            "60000/60000 [==============================] - 45s 746us/step - loss: 0.2916 - acc: 0.8948\n",
            "Epoch 37/40\n",
            "60000/60000 [==============================] - 45s 750us/step - loss: 0.2929 - acc: 0.8932\n",
            "Epoch 38/40\n",
            "60000/60000 [==============================] - 45s 745us/step - loss: 0.2914 - acc: 0.8954\n",
            "Epoch 39/40\n",
            "60000/60000 [==============================] - 45s 746us/step - loss: 0.2877 - acc: 0.8960\n",
            "Epoch 40/40\n",
            "60000/60000 [==============================] - 44s 740us/step - loss: 0.2880 - acc: 0.8959\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f66e1d98dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qxb4kSXZVLBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluate the trained model with Test Data set\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8__PjB9IVOBf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "338f1737-5273-40d8-c37f-a8a178a7c2ee"
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.02722010022941977, 0.994]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON6w0-QDZ0ri",
        "colab_type": "text"
      },
      "source": [
        "Accuray is 99.4. Number of parameters is 15520\n",
        "CONCLUSION- Retained accuracy of 99.4 with good reduction in parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0yAYjmUZ0JO",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}